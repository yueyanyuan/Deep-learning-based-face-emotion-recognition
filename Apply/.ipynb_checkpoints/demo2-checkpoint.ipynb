{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 图像采集和处理库\n",
    "import cv2    #OpenCV库\n",
    "import imutils #配合OpenCV\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array # 图片转化成数组\n",
    "\n",
    "# 加载模型所需库\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决模型加载出现的问题\n",
    "# def swish_activation(x):\n",
    "#         return (K.sigmoid(x) * x)\n",
    "# get_custom_objects().update({'swish_activation': Activation(swish_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据和图像的参数\n",
    "emotion_model_path = '../Models/Third1.h5' # 预训练模型\n",
    "detection_model_path = '../Haarcascade/haarcascade_frontalface_default.xml' # 人脸Haar特征分类器\n",
    "EMOTIONS = [\"Angry\" ,\"Disgust\",\"Fear\", \"Happy\", \"Sad\", \"Surprise\",\"Neutral\"] # 情绪类别\n",
    "\n",
    "# 加载模型、建立人脸检测器\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path) # 人脸检测的一个级联分类器\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False) # 加载预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现实时的人脸情绪识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) # 打开笔记本摄像头\n",
    "while True:\n",
    "    frame = camera.read()[1] # 读取视频帧\n",
    "    #修改图像的大小\n",
    "    frame = imutils.resize(frame,width=800)\n",
    "    #颜色空间转换，灰度图\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #检测出图片中所有的人脸，并将人脸用vector保存各个人脸的坐标、大小（用矩形表示），函数由分类器对象调用\n",
    "    #scaleFactor表示每次图像尺寸减小的比例，minSize为目标的最小尺寸\n",
    "    #minNeighbors表示每一个目标至少要被检测到5次才算是真的目标(因为周围的像素和不同的窗口大小都可以检测到人脸)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=5,minSize=(48,48), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    #scaleFactor=1.1,minNeighbors=6,minSize=(48,48)\n",
    "\n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")    #返回给定形状和类型的新数组，用零填充。\n",
    "\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "\n",
    "        (X, Y, W, H) = faces\n",
    "        \n",
    "        #从灰度图像中提取人脸的面部关键点，将其调整为固定的48*48像素（预训练模型形状）\n",
    "        #通过 CNN 进行分类的面部\n",
    "        facial = gray[Y:Y + H, X:X + W]\n",
    "        facial = cv2.resize(facial, (48, 48))\n",
    "        facial = facial.astype(\"float\") / 255.0\n",
    "        facial = img_to_array(facial, data_format=\"channels_first\")#data_format=\"channels_first\"\n",
    "        facial = np.expand_dims(facial, axis=0)\n",
    "        \n",
    "#         preds = emotion_classifier.predict(facial)[0]\n",
    "#         label = EMOTIONS[preds.argmax()]\n",
    "#         print(label)\n",
    "        \n",
    "        preds = emotion_classifier.predict(facial)[0]\n",
    "        \n",
    "        # 1. Add prediction probabilities 添加预测概率\n",
    "        cv2.putText(frameClone, \"----------------\",(20,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Emotional report : Face #\" + str(1),(20,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Angry : \" + str(round(preds[0],3)),(20,100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Disgust : \" + str(round(preds[1],3)),(20,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Fear : \" + str(round(preds[2],3)),(20,140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Happy : \" + str(round(preds[3],3)),(20,160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Sad : \" + str(round(preds[4],3)),(20,180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Surprise : \" + str(round(preds[5],3)),(20,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Neutral : \" + str(round(preds[6],3)),(20,220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        \n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "        # construct the label text\n",
    "        text = \"{}: {:.2f}% \".format(emotion, prob * 100)       \n",
    "        w = int(prob * 300)\n",
    "        cv2.rectangle(canvas, (7, (i * 35) + 5), (w, (i * 35) + 35), (255, 0, 0), -1)\n",
    "        cv2.putText(frameClone,label,(X, Y - 30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frameClone, (X, Y), (X + W, Y + H), (255, 0, 0), 2)\n",
    "                \n",
    "                \n",
    "    cv2.imshow('Emotion Status', frameClone)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smile_cascade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-029ed748211a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m## 微笑检测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# 用微笑级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msmiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmile_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_area\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1.16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCASCADE_SCALE_IMAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mew\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m#画出微笑框，红色（BGR色彩体系），画笔宽度为1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'smile_cascade' is not defined"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../Haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_eye.xml')\n",
    "\n",
    "smile_cascade = cv2.CascadeClassifier('../Haarcascade/haarcascade_smile.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # 获取摄像头拍摄到的画面\n",
    "    ret, frame = cap.read()\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 2)\n",
    "    img = frame\n",
    "    for (x,y,w,h) in faces:\n",
    "    \t# 画出人脸框，蓝色，画笔宽度微\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \t# 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源\n",
    "        face_area = img[y:y+h, x:x+w]\n",
    "        \n",
    "        ## 人眼检测\n",
    "        # 用人眼级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表\n",
    "#         eyes = eye_cascade.detectMultiScale(face_area,1.3,10)\n",
    "#         for (ex,ey,ew,eh) in eyes:\n",
    "#             #画出人眼框，绿色，画笔宽度为1\n",
    "#             cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(0,255,0),1)\n",
    "        \n",
    "        ## 微笑检测\n",
    "        # 用微笑级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表\n",
    "        smiles = smile_cascade.detectMultiScale(face_area,scaleFactor= 1.16,minNeighbors=65,minSize=(25, 25),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        for (ex,ey,ew,eh) in smiles:\n",
    "            #画出微笑框，红色（BGR色彩体系），画笔宽度为1\n",
    "            cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(0,0,255),1)\n",
    "            cv2.putText(img,'Smile',(x,y-7), 3, 1.2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "\t# 实时展示效果画面\n",
    "    cv2.imshow('frame2',img)\n",
    "    # 每5毫秒监听一次键盘动作\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 最后，关闭所有窗口\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 544.806,
   "position": {
    "height": "627px",
    "left": "915.653px",
    "right": "20px",
    "top": "53px",
    "width": "675px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
