{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "\n",
    "def swish_activation(x):\n",
    "        return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish_activation': Activation(swish_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for loading data and images 加载数据和图像的参数\n",
    "#pre-trained model 预训练模型\n",
    "detection_model_path = 'Haarcascade/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'Models/emotion_model_2.h5'\n",
    "\n",
    "# hyper-parameters for bounding boxes shape 边界框形状的超参数\n",
    "# loading models 加载模型\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"Angry\" ,\"Disgust\",\"Fear\", \"Happy\", \"Sad\", \"Surprise\",\"Neutral\"]\n",
    "# cv2.ocl.setUseOpenCL(False)\n",
    "feelings_faces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    #reading the frame 读取帧\n",
    "    frame = camera.read()[1]\n",
    "    #修改图像的大小\n",
    "    frame = imutils.resize(frame,width=800)\n",
    "    #颜色空间转换，灰度图\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #检测出图片中所有的人脸，并将人脸用vector保存各个人脸的坐标、大小（用矩形表示），函数由分类器对象调用\n",
    "    #scaleFactor表示每次图像尺寸减小的比例，minSize为目标的最小尺寸\n",
    "    #minNeighbors表示每一个目标至少要被检测到5次才算是真的目标(因为周围的像素和不同的窗口大小都可以检测到人脸)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=6,minSize=(48,48),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")    #返回给定形状和类型的新数组，用零填充。\n",
    "\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "\n",
    "        (X, Y, W, H) = faces\n",
    "        \n",
    "        #从灰度图像中提取人脸的面部关键点，将其调整为固定的48*48像素（预训练模型形状）\n",
    "        #通过 CNN 进行分类的面部\n",
    "        facial = gray[Y:Y + H, X:X + W]\n",
    "        facial = cv2.resize(facial, (48, 48))\n",
    "        facial = facial.astype(\"float\") / 255.0\n",
    "        facial = img_to_array(facial, data_format=\"channels_first\")#data_format=\"channels_first\"\n",
    "        facial = np.expand_dims(facial, axis=0)\n",
    "        \n",
    "#         preds = emotion_classifier.predict(facial)[0]\n",
    "#         label = EMOTIONS[preds.argmax()]\n",
    "#         print(label)\n",
    "        \n",
    "        preds = emotion_classifier.predict(facial)[0]\n",
    "        \n",
    "        # 1. Add prediction probabilities 添加预测概率\n",
    "        cv2.putText(frameClone, \"----------------\",(20,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Emotional report : Face #\" + str(1),(20,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Angry : \" + str(round(preds[0],3)),(20,100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Disgust : \" + str(round(preds[1],3)),(20,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(frameClone, \"Fear : \" + str(round(preds[2],3)),(20,140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Happy : \" + str(round(preds[3],3)),(20,160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Sad : \" + str(round(preds[4],3)),(20,180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Surprise : \" + str(round(preds[5],3)),(20,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(frameClone, \"Neutral : \" + str(round(preds[6],3)),(20,220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        \n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "        # construct the label text\n",
    "        text = \"{}: {:.2f}% \".format(emotion, prob * 100)       \n",
    "        w = int(prob * 300)\n",
    "        cv2.rectangle(canvas, (7, (i * 35) + 5), (w, (i * 35) + 35), (255, 0, 0), -1)\n",
    "        cv2.putText(frameClone,label,(X, Y - 30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frameClone, (X, Y), (X + W, Y + H), (255, 0, 0), 2)\n",
    "                \n",
    "                \n",
    "    cv2.imshow('Emotion Status', frameClone)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 544.806,
   "position": {
    "height": "627px",
    "left": "915.653px",
    "right": "20px",
    "top": "53px",
    "width": "675px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
